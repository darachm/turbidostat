### Scripts to monitor active turbidostat runs

These scripts are designed for a scenario where one or more
turbidostats are connected by USB to a "data logger" computer that
logs the output of each turbidostat to a separate data file. These
data files are copied to another "web server" computer, where they are
analyzed to produce a web page of useful graphs. We use a Mac for the
"data logger" computer and a Linux "web server" computer, but other
configurations are possible.

Below, we describe:
* How to set up directory structure for a turbidostat experiment
* How to use `copy-run.sh` to copy data automatically from the "data logger" to the "web server"
* How to use `analyze-run.sh` to monitor copied data and re-run an analysis script when needed
* How to use `analysis-turbidostat.R` to create a web page with plots of turbidity and growth

#### Directory structure for turbidostat experiments

On the "data logger" computer, each turbidostat experiment has a
separate directory, and each individual turbidostat has a
sub-directory within the experiment directory. For example, we might
set up two turbidostats in the following way:

For the "left" turbidostat, connected to `/dev/tty.usbmodem1421`
```
data-logger:~ tstat$ mkdir tstat-2018-01-23
data-logger:~ tstat$ cd tstat-2018-01-23
data-logger:tstat-2018-01-23 tstat$ mkdir left
data-logger:tstat-2018-01-23 tstat$ cd left
data-logger:left tstat$ screen -L /dev/tty.usbmodem1421
```

In a separate `Terminal.app` window, for the "right" turbidostat
connected to `/dev/tty.usbmodem1431`
```
data-logger:~ tstat$ cd tstat-2018-01-23
data-logger:tstat-2018-01-23 tstat$ mkdir right
data-logger:right tstat$ cd right
data-logger:right tstat$ screen -L /dev/tty.usbmodem1431
```

The final directory structure is then
```
tstat-2018-01-23
 \_ left
     \_ screenlog.0
 \_ right
     \_ screenlog.0
```

#### Automatically copying turbidostat data

The `copy-run.sh` script runs on the "data logger" computer and
periodically copies data to the "web server" computer. Edit the
`copy-run.sh` script to specify the destination directory on the "web
server" computer. For a user named `tstat` on the computer
`web-server.ingolia-lab.org`, we might use:

```
DEST="tstat@web-server.ingolia-lab.org:data/"
```

##### Creating a public/private key pair for data transfer (just once)

We create a special user account on the "web server" computer and
configure SSH public key logins from the "data logger" computer to the
"web server" computer. The examples below assume that the turbidostat
data account is named `tstat`.

On the "data logger" computer, create a public/private key pair and
copy the public key to the `tstat` account on the "web server":

```
ssh-keygen
data-logger:~ tstat$ ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/Users/tstat/.ssh/id_rsa): 
Created directory '/Users/tstat/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /Users/tstat/.ssh/id_rsa.
Your public key has been saved in /Users/tstat/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:KhsyjWFWSXCnrxbBDZTEONCHNxDlh/tmmzGDEnepgl8 tstat@data-logger.local
The key's randomart image is:
+---[RSA 2048]----+
|.o+@B..          |
|  ==*B           |
|   +O.o          |
|   . = .         |
|  = + + S        |
| + * B .         |
|. * E O          |
| . B * *         |
|  . . o          |
+----[SHA256]-----+
data-logger:~ tstat$ scp ~/.ssh/id_rsa.pub web-server:data-logger-id_rsa.pub
ZZZ
```

On the "web server" computer, add the public key 
ZZZ

##### Setting up automatic data transfer (each experiment)

In a separate `Terminal.app` window on the "data logger" computer,
unlock the private key for data transfer and start the data transfer
script:
```
data-logger:~ tstat$ ssh-add
Enter passphrase for /Users/tstat/.ssh/id_rsa: 
Identity added: /Users/tstat/.ssh/id_rsa (/Users/tstat/.ssh/id_rsa)
data-logger:~ tstat$ ~/scripts/copy-run.sh
ZZZ
```

#### Automatically analyzing turbidostat data

The `analyze-run.sh` script runs on the "web server" computer, watches
for updated data copied over from the "data logger" computer, and runs
an analysis script.

##### Analysis configuration (just once)

The `analyze-run.sh` script must be configured with the web-accessible
output location, writable by the user running the script, as well as
the path to the R analysis script itself. These two file paths are
specified in variables at the top of the `analyze-run.sh` script.

For example, if the `tstat` user's home directory is
`/zpool/home/tstat/` and the scripts are located in the
`turbidostat/analysis/online/` directory within their homedir:
```
#!/bin/bash

export WWWPATH="/var/www/tstat/"
export ANALYSIS="/zpool/home/tstat/turbidostat/analysis/online/analysis-turbidostat.R"
...
```

Verify the configuration of the `analyze-run.sh` script by running it
in the foreground:
```
tstat@web-server:~ > ~/turbidostat/analysis/online/analyze-run.sh ~/data/tstat-2018-01-23
ZZZ
...
```

##### Automatic analysis (each experiment)

Run the `analyze-run.sh` script as an ongoing, background process on
the "web server" computer:
```
tstat@web-server:~ > nohup ~/turbidostat/analysis/online/analyze-run.sh ~/data/tstat-2018-01-23 &
[1] 3141
appending output to nohup.out
tstat@web-server:~ > 
```

Any output from the analysis will be written to the `nohup.out` file,
and the script will keep looping even after you log out. When you
ultimately want to stop the analysis script, use `ps` to find the
process ID of your analysis script (3141 in the example above) and
`kill` it:
```
tstat@web-server:~ > kill 3141
```

